# ═══════════════════════════════════════════════════════════════════════════════
# SAHOOL CI/CD Pipeline
# Continuous Integration for SAHOOL Platform v16.0.0
# Updated for apps/services structure
# ═══════════════════════════════════════════════════════════════════════════════

name: CI Pipeline

on:
  push:
    branches: [main, develop, "feature/**", "release/**", "claude/**"]
  pull_request:
    branches: [main, develop]

# Restrict default permissions for all jobs
permissions:
  contents: read
  actions: read

env:
  PYTHON_VERSION: "3.11"
  NODE_VERSION: "20"
  REGISTRY: ghcr.io

jobs:
  # ─────────────────────────────────────────────────────────────────────────────
  # Code Quality Checks
  # ─────────────────────────────────────────────────────────────────────────────
  lint:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Python linters
        run: |
          pip install --upgrade pip
          pip install ruff black isort mypy

      - name: Run Ruff (Python linter)
        run: ruff check apps/ shared/ packages/ --output-format=github
        continue-on-error: true

      - name: Run Black (Python formatter check)
        run: black --check apps/ shared/ packages/
        continue-on-error: true

  # ─────────────────────────────────────────────────────────────────────────────
  # Unified Tests with Coverage (Sprint 2) - Enhanced with Coverage Regression
  # ─────────────────────────────────────────────────────────────────────────────
  test-unified:
    name: Tests with Coverage (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    needs: lint
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11', '3.12']
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history for coverage comparison

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'  # Enable pip caching

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install pytest pytest-asyncio pytest-cov pytest-xdist httpx pyjwt fastapi pydantic jsonschema sqlalchemy tortoise-orm structlog

      - name: Run unified tests with coverage (parallel)
        run: |
          # Run service tests in parallel using pytest-xdist
          pytest apps/services/ -v -n auto --tb=short --ignore=apps/services/marketplace-service \
            --cov=apps/services --cov=shared --cov-report=xml --cov-report=term-missing || true

          # Run shared module tests
          pytest tests/smoke/ tests/integration/test_health.py -v --tb=short \
            --cov-append --cov=shared --cov-report=xml --cov-report=term-missing || true

          # Run unit tests for shared modules
          pytest tests/unit/ -v --tb=short \
            --cov-append --cov=shared --cov-report=xml --cov-report=term-missing || true
        env:
          ENVIRONMENT: test
          PYTHONPATH: .
          JWT_SECRET_KEY: test-secret-key-for-unit-tests-only-32chars
          JWT_ALGORITHM: HS256
          DATABASE_URL: ""
          NATS_URL: ""

      - name: Check coverage regression
        if: github.event_name == 'pull_request'
        run: |
          # Get current coverage percentage
          CURRENT_COV=$(python -c "import xml.etree.ElementTree as ET; tree = ET.parse('coverage.xml'); print(tree.getroot().attrib['line-rate'])" 2>/dev/null || echo "0")
          CURRENT_COV_PCT=$(python -c "print(f'{float($CURRENT_COV) * 100:.2f}')" 2>/dev/null || echo "0")

          echo "Current coverage: ${CURRENT_COV_PCT}%"

          # Minimum coverage threshold - enforced to maintain code quality
          # TODO: Gradually increase this threshold as more tests are added
          # Current baseline: 3% (as of Jan 2026) - target: 60%
          MIN_COVERAGE=3.0

          # Check if coverage meets minimum - FAIL if below threshold
          python -c "
          import sys
          current = float('${CURRENT_COV_PCT}' or '0')
          minimum = float('${MIN_COVERAGE}')
          if current < minimum:
              print(f'::error::Coverage {current:.2f}% is below minimum {minimum:.2f}%')
              print(f'Please increase test coverage to at least {minimum:.2f}%')
              sys.exit(1)
          else:
              print(f'✅ Coverage {current:.2f}% meets minimum {minimum:.2f}%')
          "

      - name: Upload coverage report
        uses: codecov/codecov-action@v4
        if: always()
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          fail_ci_if_error: false
          flags: unittests
          name: codecov-sahool

      - name: Upload coverage artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report-py${{ matrix.python-version }}
          path: coverage.xml
          retention-days: 30

  # ─────────────────────────────────────────────────────────────────────────────
  # Architecture Check (Sprint 3)
  # ─────────────────────────────────────────────────────────────────────────────
  arch-check:
    name: Architecture Check
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Check architecture import rules
        run: python -m tools.arch.check_imports --root .
        continue-on-error: true

      - name: Run architecture smoke tests
        run: |
          pip install pytest pytest-cov
          pytest tests/smoke/test_arch_imports.py -v
        continue-on-error: true
        env:
          PYTHONPATH: .

  # ─────────────────────────────────────────────────────────────────────────────
  # Event Governance Check (Sprint 4)
  # ─────────────────────────────────────────────────────────────────────────────
  event-check:
    name: Event Governance
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install pydantic jsonschema pytest pytest-cov

      - name: Validate event schemas
        run: |
          if [ -d "packages/shared/events" ]; then
            echo "Validating event schemas..."
            python -c "import json; import os; [json.load(open(os.path.join('packages/shared/events', f))) for f in os.listdir('packages/shared/events') if f.endswith('.json')]"
            echo "✅ Event schemas are valid JSON"
          else
            echo "No event schemas directory found"
          fi
        env:
          PYTHONPATH: .

  # ─────────────────────────────────────────────────────────────────────────────
  # Python Tests (Service-specific)
  # ─────────────────────────────────────────────────────────────────────────────
  test-python:
    name: Python Tests (${{ matrix.service }} - Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    needs: lint
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11', '3.12']
        service:
          - apps/services/satellite-service
          - apps/services/crop-growth-model
          - apps/services/indicators-service
          - apps/services/weather-advanced
          - apps/services/iot-service
          # crop-health-ai DEPRECATED - replaced by crop-intelligence-service
          - apps/services/crop-intelligence-service
          - apps/services/fertilizer-advisor
          - apps/services/irrigation-smart
          - apps/services/yield-engine
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          if [ -f "${{ matrix.service }}/requirements.txt" ]; then
            pip install -r ${{ matrix.service }}/requirements.txt
          fi
          # Pin pytest-asyncio to compatible version (0.23.x for asyncio_mode support)
          pip install pytest "pytest-asyncio>=0.23.0,<1.0.0" pytest-cov httpx fastapi pydantic

      - name: Run tests
        run: |
          if [ -d "${{ matrix.service }}/tests" ]; then
            if find "${{ matrix.service }}/tests" -name "test_*.py" -o -name "*_test.py" | grep -q .; then
              PYTHONPATH=$PWD pytest ${{ matrix.service }}/tests -v --tb=short
            else
              echo "No test files found in ${{ matrix.service }}/tests - skipping tests"
            fi
          else
            echo "No tests directory found for ${{ matrix.service }}"
          fi
        env:
          ENVIRONMENT: test
          DATABASE_URL: ""
          NATS_URL: ""

  # ─────────────────────────────────────────────────────────────────────────────
  # Node.js Tests (Service-specific)
  # ─────────────────────────────────────────────────────────────────────────────
  test-node:
    name: Node.js Tests (${{ matrix.service }} - Node ${{ matrix.node-version }})
    runs-on: ubuntu-latest
    needs: lint
    strategy:
      fail-fast: false
      matrix:
        node-version: ['20', '22']
        service:
          - apps/services/field-management-service
          - apps/services/marketplace-service
          - apps/services/chat-service
          - apps/services/code-review-agent
          - apps/services/user-service
          - apps/services/research-core
          - apps/services/field-core
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
          cache-dependency-path: '**/package-lock.json'

      - name: Install root dependencies
        run: npm ci --ignore-scripts || npm install --ignore-scripts
        continue-on-error: true

      - name: Install service dependencies
        run: |
          if [ -f "${{ matrix.service }}/package.json" ]; then
            cd ${{ matrix.service }}
            npm ci --ignore-scripts || npm install --ignore-scripts
          fi
        continue-on-error: true

      - name: Generate Prisma client
        run: |
          if [ -f "${{ matrix.service }}/prisma/schema.prisma" ]; then
            cd ${{ matrix.service }}
            npx prisma generate
          fi
        continue-on-error: true

      - name: Run tests
        run: |
          if [ -f "${{ matrix.service }}/package.json" ]; then
            cd ${{ matrix.service }}
            if grep -q '"test"' package.json; then
              npm test || echo "Tests completed with warnings"
            else
              echo "No test script found in ${{ matrix.service }}/package.json"
            fi
          else
            echo "No package.json found for ${{ matrix.service }}"
          fi
        env:
          ENVIRONMENT: test
          NODE_ENV: test
          DATABASE_URL: ""
          NATS_URL: ""
          JWT_SECRET_KEY: test-secret-key-for-unit-tests-only-32chars
          JWT_ALGORITHM: HS256

  # ─────────────────────────────────────────────────────────────────────────────
  # Build Docker Images
  # Only build on main/develop to avoid Docker Hub rate limiting on feature branches
  # ─────────────────────────────────────────────────────────────────────────────
  build:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [test-python, test-node]
    # Only build Docker images on main/develop pushes to avoid rate limiting
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')
    strategy:
      fail-fast: false
      matrix:
        service:
          - name: satellite-service
            path: apps/services/satellite-service
          - name: crop-growth-model
            path: apps/services/crop-growth-model
          - name: indicators-service
            path: apps/services/indicators-service
          - name: weather-advanced
            path: apps/services/weather-advanced
          - name: crop-intelligence-service
            path: apps/services/crop-intelligence-service
          - name: fertilizer-advisor
            path: apps/services/fertilizer-advisor
          - name: irrigation-smart
            path: apps/services/irrigation-smart
          - name: yield-engine
            path: apps/services/yield-engine
          - name: notification-service
            path: apps/services/notification-service
          - name: marketplace-service
            path: apps/services/marketplace-service
    steps:
      - name: Free up disk space
        run: |
          echo "Disk space before cleanup:"
          df -h
          # Remove unnecessary files to free up space
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo docker image prune --all --force || true
          echo "Disk space after cleanup:"
          df -h

      - name: Checkout code
        uses: actions/checkout@v4

      # Login to Docker Hub BEFORE setup-buildx to avoid rate limiting when pulling buildkit image
      # Configure DOCKERHUB_USERNAME and DOCKERHUB_TOKEN secrets for better reliability
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
        continue-on-error: true

      # Pre-pull buildkit image with retries to avoid setup-buildx failures
      - name: Pre-pull BuildKit image
        run: |
          for i in 1 2 3 4; do
            echo "Attempt $i: Pulling moby/buildkit:v0.12.5..."
            if docker pull moby/buildkit:v0.12.5; then
              echo "✅ Successfully pulled buildkit image"
              exit 0
            fi
            echo "⚠️ Pull failed, waiting $((i * 5)) seconds before retry..."
            sleep $((i * 5))
          done
          echo "❌ Failed to pull buildkit after 4 attempts, continuing anyway..."
        continue-on-error: true

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          # Pin buildkit version for reliability and cache efficiency (avoid :latest rate limiting)
          driver-opts: |
            image=moby/buildkit:v0.12.5
            network=host
        env:
          DOCKER_BUILD_SUMMARY: false

      - name: Check Dockerfile exists
        id: check-dockerfile
        run: |
          if [ -f "${{ matrix.service.path }}/Dockerfile" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "No Dockerfile found for ${{ matrix.service.name }}"
          fi

      - name: Build Docker image
        if: steps.check-dockerfile.outputs.exists == 'true'
        uses: docker/build-push-action@v5
        with:
          # Use repository root as context for shared module access
          context: .
          file: ${{ matrix.service.path }}/Dockerfile
          push: false
          tags: sahool/${{ matrix.service.name }}:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # ─────────────────────────────────────────────────────────────────────────────
  # Environment Validation (Sprint 1 Governance)
  # ─────────────────────────────────────────────────────────────────────────────
  env-validation:
    name: ENV Validation
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Validate ENV configuration
        run: |
          if [ -f "tools/env/validate_env.py" ]; then
            cp .env.example .env 2>/dev/null || true
            # Run validation (informational in CI - doesn't fail build)
            python tools/env/validate_env.py || echo "⚠️ Some environment variables need attention in production"
          else
            echo "ENV validation script not found - skipping"
          fi
        continue-on-error: true

  # ─────────────────────────────────────────────────────────────────────────────
  # Security Scan
  # ─────────────────────────────────────────────────────────────────────────────
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install security tools
        run: |
          pip install safety bandit detect-secrets

      - name: Run Bandit (Python security linter)
        run: bandit -r apps/ shared/ -ll -x "**/tests/**" || true

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: 'fs'
          scan-ref: '.'
          severity: 'HIGH,CRITICAL'
          exit-code: '0'

      - name: Check for private keys in repository
        run: |
          echo "Checking for private keys..."
          FOUND_KEYS=$(find . -type f \( -name "*.pem" -o -name "*.key" -o -name "*.p12" -o -name "*.pfx" \) -not -path "./.git/*" -not -path "./node_modules/*" 2>/dev/null || true)
          if [ -n "$FOUND_KEYS" ]; then
            echo "Private keys found in repository:"
            echo "$FOUND_KEYS"
            exit 1
          fi
          echo "No private keys found"

  # ─────────────────────────────────────────────────────────────────────────────
  # Governance Structure Validation
  # ─────────────────────────────────────────────────────────────────────────────
  governance:
    name: Governance Check
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install PyYAML
        run: pip install pyyaml

      - name: Validate services.yaml
        run: |
          python -c "import yaml; yaml.safe_load(open('governance/services.yaml'))"
          echo "services.yaml is valid YAML"

      - name: Check services exist
        run: |
          echo "Verifying service directories..."
          for dir in apps/services/*/; do
            if [ -d "$dir" ]; then
              echo "✅ Found: $dir"
            fi
          done

      - name: Check event schemas
        run: |
          if [ -d "packages/shared/events" ]; then
            count=$(ls packages/shared/events/*.json 2>/dev/null | wc -l)
            echo "Found $count event schema files"
          fi

  # ─────────────────────────────────────────────────────────────────────────────
  # Integration Test (Docker Compose)
  # ─────────────────────────────────────────────────────────────────────────────
  integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
    env:
      # Default values for CI - secrets override these if available
      POSTGRES_USER: postgres
      POSTGRES_DB: sahool
      JWT_ALGORITHM: HS256
    steps:
      - name: Free up disk space
        run: |
          echo "Disk space before cleanup:"
          df -h
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo docker image prune --all --force || true
          echo "Disk space after cleanup:"
          df -h

      - name: Checkout code
        uses: actions/checkout@v4

      - name: Verify Docker Compose
        run: docker compose version

      - name: Create .env file for Docker Compose
        run: |
          # CI test defaults - these are ONLY used for integration testing
          # In production, proper secrets must be configured
          echo "POSTGRES_USER=postgres" > .env
          echo "POSTGRES_PASSWORD=test_postgres_password_ci" >> .env
          echo "POSTGRES_DB=sahool" >> .env
          echo "REDIS_PASSWORD=test_redis_password_ci" >> .env
          echo "JWT_SECRET_KEY=test_jwt_secret_key_for_ci_only_32chars" >> .env
          echo "JWT_ALGORITHM=HS256" >> .env
          echo "MQTT_PASSWORD=test_mqtt_password_ci" >> .env
          echo "GRAFANA_ADMIN_PASSWORD=test_grafana_password_ci" >> .env
          echo "ETCD_ROOT_USERNAME=root" >> .env
          echo "ETCD_ROOT_PASSWORD=test_etcd_password_ci_32chars_min" >> .env
          echo "NATS_USER=sahool_app_ci" >> .env
          echo "NATS_PASSWORD=test_nats_password_ci_32_chars_min" >> .env
          echo "NATS_ADMIN_USER=nats_admin_ci" >> .env
          echo "NATS_ADMIN_PASSWORD=test_nats_admin_password_ci_32_chars" >> .env
          echo "NATS_MONITOR_USER=nats_monitor_ci" >> .env
          echo "NATS_MONITOR_PASSWORD=test_nats_monitor_password_ci_32_chars" >> .env
          echo "NATS_CLUSTER_USER=nats_cluster_ci" >> .env
          echo "NATS_CLUSTER_PASSWORD=test_nats_cluster_password_ci_32_chars" >> .env
          echo "NATS_SYSTEM_USER=nats_system_ci" >> .env
          echo "NATS_SYSTEM_PASSWORD=test_nats_system_password_ci_32_chars" >> .env
          echo "NATS_JETSTREAM_KEY=test_jetstream_key_ci_32_chars_min" >> .env
          echo "MINIO_ROOT_USER=test_minio_ci_user" >> .env
          echo "MINIO_ROOT_PASSWORD=test_minio_ci_password_32chars_min" >> .env
          cat .env
          echo "✅ Created .env file"

      - name: Start services
        run: |
          docker compose up -d postgres nats redis
          sleep 15

      - name: Check services health
        run: |
          docker compose ps
          docker compose logs --tail=50

      - name: Stop services
        run: docker compose down -v
        if: always()
