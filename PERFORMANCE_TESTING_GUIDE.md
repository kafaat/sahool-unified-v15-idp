# Performance Testing Guide

## Ø¯Ù„ÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡

**Version**: 1.0  
**Last Updated**: 2026-01-02  
**Related**: tests/load/README.md, POST_MERGE_VERIFICATION.md

---

## ğŸ“‹ Overview | Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©

This guide provides comprehensive instructions for performance testing the SAHOOL platform using the k6 load testing framework added in PR #315.

ÙŠÙˆÙØ± Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø¯Ø§Ø¡ Ù…Ù†ØµØ© Ø³Ù‡ÙˆÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥Ø·Ø§Ø± Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£Ø­Ù…Ø§Ù„ k6.

---

## ğŸ¯ Testing Objectives | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±

### Primary Goals

1. **Baseline Performance**: Establish performance benchmarks for all services
2. **Capacity Planning**: Determine system limits under various load conditions
3. **Regression Detection**: Identify performance degradation in new releases
4. **Bottleneck Identification**: Find and document performance bottlenecks
5. **Resource Optimization**: Guide infrastructure scaling decisions

### Key Performance Indicators (KPIs)

- **Response Time**: p95, p99 latency for API endpoints
- **Throughput**: Requests per second (RPS)
- **Error Rate**: Percentage of failed requests
- **Resource Utilization**: CPU, Memory, Network, Disk I/O
- **Concurrent Users**: Maximum supported simultaneous users

---

## ğŸ—ï¸ Test Infrastructure | Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±

### Components

```
tests/load/
â”œâ”€â”€ scenarios/               # k6 test scenarios
â”‚   â”œâ”€â”€ smoke.js            # Minimal load validation
â”‚   â”œâ”€â”€ load.js             # Normal load testing
â”‚   â”œâ”€â”€ stress.js           # Beyond capacity testing
â”‚   â”œâ”€â”€ spike.js            # Sudden load increase
â”‚   â””â”€â”€ soak.js             # Extended duration testing
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ config.js           # Configuration management
â”‚   â””â”€â”€ helpers.js          # Utility functions
â”œâ”€â”€ simulation/             # Multi-client simulation
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ web-dashboard-simulation.js
â”‚   â”‚   â”œâ”€â”€ mobile-app-simulation.js
â”‚   â”‚   â””â”€â”€ agent-simulation.js
â”‚   â””â”€â”€ docker-compose-sim.yml
â”œâ”€â”€ grafana/                # Visualization dashboards
â”œâ”€â”€ docker-compose.load.yml # Load testing infrastructure
â””â”€â”€ run-tests.sh            # Test execution script
```

### Prerequisites

**Software Requirements:**

- Docker & Docker Compose (v2+)
- k6 (for local runs)
- 8GB+ RAM recommended
- 4+ CPU cores recommended

**Infrastructure Requirements:**

- SAHOOL platform running (all services)
- PostgreSQL database
- Redis cache
- NATS message queue
- Monitoring stack (optional but recommended)

---

## ğŸš€ Quick Start | Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹

### 1. Start SAHOOL Platform

```bash
# Using docker-one-by-one script (recommended for resource-constrained systems)
./docker-one-by-one.sh

# OR using standard docker compose
docker compose up -d

# Verify all services are running
docker compose ps

# Check health endpoints
curl http://localhost:8080/healthz
```

### 2. Start Load Testing Infrastructure

```bash
cd tests/load

# Start InfluxDB and Grafana
docker compose -f docker-compose.load.yml up -d

# Access Grafana at http://localhost:3000
# Default credentials: admin/admin
```

### 3. Run Smoke Test

```bash
# Quick validation (minimal load)
./run-tests.sh smoke

# Expected output:
# - Test duration: ~30 seconds
# - Virtual users: 1-5
# - Success rate: 100%
```

### 4. View Results

```bash
# Grafana dashboards
open http://localhost:3000

# InfluxDB metrics
open http://localhost:8086

# Check test results directory
ls -la results/
```

---

## ğŸ“Š Test Scenarios | Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±

### 1. Smoke Test (Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¯Ø®Ø§Ù†)

**Purpose**: Verify system works with minimal load

**Configuration:**

- Duration: 30 seconds
- Virtual Users: 1-5
- Target RPS: 10-20

**Command:**

```bash
./run-tests.sh smoke
```

**Success Criteria:**

- âœ… 100% success rate
- âœ… p95 latency < 500ms
- âœ… No errors

---

### 2. Load Test (Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø­Ù…Ù„)

**Purpose**: Test system under normal expected load

**Configuration:**

- Duration: 5-10 minutes
- Virtual Users: 50-100
- Target RPS: 100-500

**Command:**

```bash
./run-tests.sh load
```

**Success Criteria:**

- âœ… 99.9% success rate
- âœ… p95 latency < 1000ms
- âœ… Error rate < 0.1%
- âœ… CPU < 70%
- âœ… Memory < 80%

---

### 3. Stress Test (Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¥Ø¬Ù‡Ø§Ø¯)

**Purpose**: Find system breaking point

**Configuration:**

- Duration: 10-20 minutes
- Virtual Users: 100-500+ (gradually increasing)
- Target RPS: 500-2000+

**Command:**

```bash
./run-tests.sh stress
```

**Success Criteria:**

- âœ… System gracefully degrades (no crashes)
- âœ… Error messages are clear
- âœ… Recovery after load reduction
- âš ï¸ Identify max capacity

---

### 4. Spike Test (Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ù…ÙØ§Ø¬Ø¦)

**Purpose**: Test system behavior with sudden traffic increase

**Configuration:**

- Duration: 5-10 minutes
- Virtual Users: 1 â†’ 500 (sudden jump)
- Target RPS: 10 â†’ 1000

**Command:**

```bash
./run-tests.sh spike
```

**Success Criteria:**

- âœ… System handles spike without crashes
- âœ… Auto-scaling triggers (if configured)
- âœ… Response times recover after spike

---

### 5. Soak Test (Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù‚Ø¹)

**Purpose**: Verify system stability over extended period

**Configuration:**

- Duration: 2-24 hours
- Virtual Users: 50-100 (constant)
- Target RPS: 100-200 (steady)

**Command:**

```bash
./run-tests.sh soak
```

**Success Criteria:**

- âœ… No memory leaks
- âœ… No connection pool exhaustion
- âœ… Consistent performance
- âœ… No resource degradation

---

## ğŸ¯ Performance Targets | Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø£Ø¯Ø§Ø¡

### API Response Times

| Endpoint Type    | p50    | p95     | p99     |
| ---------------- | ------ | ------- | ------- |
| Health Check     | <50ms  | <100ms  | <200ms  |
| Read Operations  | <100ms | <500ms  | <1000ms |
| Write Operations | <200ms | <1000ms | <2000ms |
| Complex Queries  | <500ms | <2000ms | <5000ms |
| File Uploads     | <1s    | <5s     | <10s    |

### Throughput

| Service      | Target RPS | Max RPS |
| ------------ | ---------- | ------- |
| Field Ops    | 200        | 1000    |
| Billing      | 100        | 500     |
| Satellite    | 50         | 200     |
| Weather      | 100        | 500     |
| Notification | 500        | 2000    |

### Resource Utilization

| Resource | Normal | Warning | Critical |
| -------- | ------ | ------- | -------- |
| CPU      | <50%   | 50-70%  | >70%     |
| Memory   | <60%   | 60-80%  | >80%     |
| Disk I/O | <50%   | 50-75%  | >75%     |
| Network  | <40%   | 40-60%  | >60%     |

---

## ğŸ“ˆ Monitoring & Metrics | Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØ§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³

### Real-time Dashboards

**Grafana Dashboards:**

1. **k6 Load Testing Dashboard**
   - Request rate
   - Response times (p50, p95, p99)
   - Error rate
   - Active virtual users

2. **System Resources Dashboard**
   - CPU usage per service
   - Memory consumption
   - Network traffic
   - Disk I/O

3. **Application Metrics Dashboard**
   - API endpoint latency
   - Database query performance
   - Cache hit rate
   - Queue depth

### InfluxDB Queries

```sql
-- Average response time by endpoint (with time bucketing)
SELECT mean("value") FROM "http_req_duration"
WHERE time > now() - 1h
GROUP BY time(1m), "url"

-- Error rate over time
SELECT count("value") FROM "http_req_failed"
WHERE "value" = 1 AND time > now() - 1h
GROUP BY time(1m)

-- Request rate per minute
SELECT count("value") FROM "http_reqs"
WHERE time > now() - 1h
GROUP BY time(1m)
```

---

## ğŸ” Analysis & Reporting | Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ø¥Ø¨Ù„Ø§Øº

### Post-Test Analysis

```bash
# Generate HTML report
k6 run --out json=results.json scenarios/load.js
k6 json-to-html results.json > report.html

# View results
open report.html
```

### Key Metrics to Report

1. **Performance Summary**
   - Total requests
   - Success rate
   - Average/p95/p99 response times
   - Requests per second

2. **Resource Utilization**
   - Peak CPU usage
   - Peak memory usage
   - Network bandwidth
   - Database connections

3. **Errors & Failures**
   - Error types and counts
   - Failed endpoints
   - Root cause analysis

4. **Recommendations**
   - Scaling recommendations
   - Optimization opportunities
   - Configuration changes

---

## ğŸ› Troubleshooting | Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡

### Common Issues

#### High Response Times

```bash
# Check database slow queries
docker compose logs postgres | grep "duration:"

# Check Redis performance
redis-cli --latency

# Review service logs
docker compose logs [service-name]
```

#### Memory Leaks

```bash
# Monitor memory over time
docker stats --no-stream

# Check for goroutine leaks (Go services)
curl http://localhost:6060/debug/pprof/heap

# Check for event loop blocks (Node.js services)
curl http://localhost:9229/json
```

#### Connection Pool Exhaustion

```bash
# Check database connections
SELECT count(*) FROM pg_stat_activity;

# Check Redis connections
redis-cli CLIENT LIST | wc -l
```

---

## ğŸ“ Best Practices | Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª

### Test Execution

1. **Isolate Environment**: Run tests in dedicated environment
2. **Consistent State**: Reset database between test runs
3. **Realistic Data**: Use production-like data volumes
4. **Gradual Ramp**: Increase load gradually
5. **Monitor Resources**: Watch CPU, memory, network during tests

### Test Development

1. **Parameterize**: Use environment variables for configuration
2. **Modular**: Break tests into reusable functions
3. **Assertions**: Add meaningful checks and thresholds
4. **Documentation**: Document test scenarios and expectations
5. **Version Control**: Track test changes in git

### Continuous Testing

1. **Automated Runs**: Schedule regular performance tests
2. **Baseline Comparison**: Compare against previous runs
3. **Alert on Regression**: Notify on performance degradation
4. **Track Trends**: Monitor performance over time
5. **Document Changes**: Record infrastructure/code changes

---

## ğŸ”— References | Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹

- [k6 Documentation](https://k6.io/docs/)
- [Load Testing Guide](tests/load/README.md)
- [Quick Start](tests/load/QUICKSTART.md)
- [Docker Guide](docs/DOCKER.md)
- [Post-Merge Verification](POST_MERGE_VERIFICATION.md)

---

## ğŸ“… Testing Schedule | Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±

### Recommended Frequency

| Test Type | Frequency    | Duration   |
| --------- | ------------ | ---------- |
| Smoke     | Every commit | 1 min      |
| Load      | Daily        | 10 min     |
| Stress    | Weekly       | 30 min     |
| Spike     | Weekly       | 15 min     |
| Soak      | Monthly      | 4-24 hours |

---

**Note**: Always run tests in a non-production environment first!
