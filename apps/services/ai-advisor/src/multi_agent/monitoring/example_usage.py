"""
SAHOOL Multi-Agent Performance Monitoring - Example Usage
Ù…Ø«Ø§Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ø¸Ø§Ù… Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù„ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯ Ù„Ø³Ù‡ÙˆÙ„

Demonstrates how to use the performance monitoring and feedback system
for agricultural AI agents.

ÙŠÙˆØ¶Ø­ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ø¸Ø§Ù… Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª
Ù„Ù„ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„Ø°ÙƒÙŠÙŠÙ† Ø§Ù„Ø²Ø±Ø§Ø¹ÙŠÙŠÙ†.
"""

import asyncio
from datetime import timedelta
from performance_monitor import (
    PerformanceMonitor,
    FeedbackCollector,
    FeedbackRating,
    ImprovementArea,
    PROMETHEUS_AVAILABLE,
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Example 1: Basic Performance Monitoring
# Ù…Ø«Ø§Ù„ 1: Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def example_basic_monitoring():
    """
    Basic performance monitoring example
    Ù…Ø«Ø§Ù„ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    """
    print("\n" + "="*80)
    print("Example 1: Basic Performance Monitoring")
    print("Ù…Ø«Ø§Ù„ 1: Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©")
    print("="*80 + "\n")

    # Initialize performance monitor
    monitor = PerformanceMonitor(
        max_history=1000,
        percentile_window=100,
        enable_prometheus=True
    )

    # Simulate agent requests
    agent_id = "disease-expert"

    print(f"ğŸ“Š Tracking requests for agent: {agent_id}\n")

    for i in range(10):
        # Record request
        request_id = await monitor.record_request(
            agent_id=agent_id,
            request_data={
                "agent_type": "disease_diagnosis",
                "query": f"Diagnose wheat disease {i+1}",
                "language": "ar"
            }
        )

        # Simulate processing time
        await asyncio.sleep(0.1)

        # Record response
        success = i < 9  # Fail the last one for testing
        latency = 1.5 + (i * 0.1)  # Increasing latency
        confidence = 0.85 + (i * 0.01)  # Increasing confidence

        await monitor.record_response(
            agent_id=agent_id,
            response_data={
                "diagnosis": "yellow_rust" if success else None,
                "treatment": "fungicide_application" if success else None,
            },
            success=success,
            latency=latency,
            confidence=confidence,
            tokens_used=150 + (i * 10),
            error="Model timeout" if not success else None
        )

        print(f"âœ“ Request {i+1}: {'Success' if success else 'Failed'} "
              f"(latency: {latency:.2f}s, confidence: {confidence:.2%})")

    # Get metrics
    metrics = await monitor.get_metrics(agent_id)

    print(f"\nğŸ“ˆ Agent Metrics for {agent_id}:")
    print(f"  Total Requests: {metrics.total_requests}")
    print(f"  Success Rate: {metrics.success_rate():.2f}%")
    print(f"  Error Rate: {metrics.error_rate():.2f}%")
    print(f"  Avg Response Time: {metrics.avg_response_time:.2f}s")
    print(f"  P95 Response Time: {metrics.p95_response_time:.2f}s")
    print(f"  P99 Response Time: {metrics.p99_response_time:.2f}s")
    print(f"  Avg Confidence: {metrics.avg_confidence:.2%}")
    print(f"  Total Tokens: {metrics.tokens_used}")
    print(f"  Estimated Cost: ${metrics.cost_estimate:.4f}")
    print(f"  Cost per Request: ${metrics.cost_per_request():.4f}")

    return monitor, agent_id


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Example 2: User Feedback Collection
# Ù…Ø«Ø§Ù„ 2: Ø¬Ù…Ø¹ ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def example_feedback_collection(monitor, agent_id):
    """
    User feedback collection example
    Ù…Ø«Ø§Ù„ Ø¬Ù…Ø¹ ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
    """
    print("\n" + "="*80)
    print("Example 2: User Feedback Collection")
    print("Ù…Ø«Ø§Ù„ 2: Ø¬Ù…Ø¹ ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†")
    print("="*80 + "\n")

    # Initialize feedback collector
    collector = FeedbackCollector(monitor)

    # Get recent requests
    request_ids = list(monitor._requests.keys())[-5:]

    print(f"ğŸ’¬ Collecting feedback for {len(request_ids)} requests\n")

    # Simulate user feedback
    feedback_data = [
        (5, "Excellent diagnosis! Very accurate and helpful. / ØªØ´Ø®ÙŠØµ Ù…Ù…ØªØ§Ø²! Ø¯Ù‚ÙŠÙ‚ Ø¬Ø¯Ø§Ù‹ ÙˆÙ…ÙÙŠØ¯."),
        (4, "Good response, but could be faster. / Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¬ÙŠØ¯Ø©ØŒ Ù„ÙƒÙ† ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† Ø£Ø³Ø±Ø¹."),
        (5, "Perfect! Exactly what I needed. / Ù…Ø«Ø§Ù„ÙŠ! Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ø§ Ø§Ø­ØªØ§Ø¬Ù‡."),
        (3, "Decent but unclear in some parts. / Ù„Ø§Ø¦Ù‚ Ù„ÙƒÙ† ØºÙŠØ± ÙˆØ§Ø¶Ø­ ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡."),
        (4, "Very helpful, thank you! / Ù…ÙÙŠØ¯ Ø¬Ø¯Ø§Ù‹ØŒ Ø´ÙƒØ±Ø§Ù‹!"),
    ]

    for i, (request_id, (rating, comments)) in enumerate(zip(request_ids, feedback_data)):
        feedback_id = await collector.submit_feedback(
            request_id=request_id,
            rating=rating,
            comments=comments,
            agent_id=agent_id
        )
        print(f"âœ“ Feedback {i+1}: Rating {rating}/5 - {comments[:50]}...")

    # Get feedback summary
    summary = await collector.get_feedback_summary(agent_id)

    print(f"\nğŸ“Š Feedback Summary for {agent_id}:")
    print(f"  Total Feedback: {summary['total_feedback']}")
    print(f"  Average Rating: {summary['average_rating']:.2f}/5.0")
    print(f"  Rating Distribution:")
    for rating, count in sorted(summary['rating_distribution'].items()):
        stars = "â­" * rating
        print(f"    {stars} ({rating}): {count}")

    # Get updated metrics
    metrics = await monitor.get_metrics(agent_id)
    print(f"\n  User Satisfaction Score: {metrics.user_satisfaction_score:.2f}/5.0")

    return collector


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Example 3: Accuracy Tracking
# Ù…Ø«Ø§Ù„ 3: ØªØªØ¨Ø¹ Ø§Ù„Ø¯Ù‚Ø©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def example_accuracy_tracking(monitor, collector, agent_id):
    """
    Accuracy tracking example
    Ù…Ø«Ø§Ù„ ØªØªØ¨Ø¹ Ø§Ù„Ø¯Ù‚Ø©
    """
    print("\n" + "="*80)
    print("Example 3: Accuracy Tracking")
    print("Ù…Ø«Ø§Ù„ 3: ØªØªØ¨Ø¹ Ø§Ù„Ø¯Ù‚Ø©")
    print("="*80 + "\n")

    # Get some requests for accuracy testing
    request_ids = list(monitor._requests.keys())[:8]

    print(f"ğŸ¯ Submitting actual outcomes for {len(request_ids)} requests\n")

    # Simulate actual outcomes
    actual_outcomes = [
        "yellow_rust",
        "yellow_rust",
        "yellow_rust",
        "brown_rust",  # This one is different
        "yellow_rust",
        "yellow_rust",
        "yellow_rust",
        "yellow_rust",
    ]

    for i, (request_id, actual) in enumerate(zip(request_ids, actual_outcomes)):
        await collector.submit_outcome(
            request_id=request_id,
            actual_result=actual,
            agent_id=agent_id
        )

        # Get predicted result
        request = monitor._requests[request_id]
        predicted = request.response_data.get('diagnosis') if request.response_data else None

        match = "âœ“" if predicted == actual else "âœ—"
        print(f"{match} Request {i+1}: Predicted={predicted}, Actual={actual}")

    # Calculate accuracy
    accuracy_outcomes = list(zip(request_ids, actual_outcomes))
    accuracy = await monitor.calculate_accuracy(agent_id, accuracy_outcomes)

    print(f"\nğŸ“Š Accuracy Metrics:")
    print(f"  Accuracy Score: {accuracy:.2%}")
    print(f"  Correct Predictions: 7/8")
    print(f"  Incorrect Predictions: 1/8")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Example 4: Performance Recommendations
# Ù…Ø«Ø§Ù„ 4: ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def example_recommendations(monitor, collector, agent_id):
    """
    Performance recommendations example
    Ù…Ø«Ø§Ù„ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
    """
    print("\n" + "="*80)
    print("Example 4: Performance Recommendations")
    print("Ù…Ø«Ø§Ù„ 4: ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡")
    print("="*80 + "\n")

    # Get recommendations
    recommendations = await monitor.get_recommendations(
        agent_id=agent_id,
        threshold_response_time=2.0,
        threshold_accuracy=0.9,
        threshold_satisfaction=4.5
    )

    print(f"ğŸ’¡ Performance Recommendations ({len(recommendations)} found):\n")

    for i, rec in enumerate(recommendations, 1):
        severity_emoji = {
            'high': 'ğŸ”´',
            'medium': 'ğŸŸ¡',
            'low': 'ğŸŸ¢'
        }.get(rec.get('severity', 'low'), 'âšª')

        print(f"{severity_emoji} Recommendation {i}:")
        print(f"  Area: {rec['area']} / {rec.get('area_ar', '')}")
        print(f"  Severity: {rec.get('severity', 'N/A')}")
        print(f"  Current: {rec.get('current_value', 'N/A')}")
        print(f"  Target: {rec.get('target_value', 'N/A')}")
        print(f"  Suggestion: {rec['suggestion']}")
        if 'suggestion_ar' in rec:
            print(f"  Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø­: {rec['suggestion_ar']}")
        print()

    # Get improvement areas from feedback
    improvement_areas = await collector.identify_improvement_areas(agent_id)

    print(f"ğŸ” Improvement Areas Identified ({len(improvement_areas)} areas):\n")

    for i, area in enumerate(improvement_areas, 1):
        print(f"{i}. {area.get('area', 'unknown').upper()}")
        if 'mentions' in area:
            print(f"   User Mentions: {area['mentions']}")
            print(f"   Priority: {area.get('priority', 'N/A')}")
        if 'suggestion' in area:
            print(f"   Suggestion: {area['suggestion']}")
        print()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Example 5: Multi-Agent Monitoring
# Ù…Ø«Ø§Ù„ 5: Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯ÙŠÙ†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def example_multi_agent_monitoring():
    """
    Multi-agent monitoring example
    Ù…Ø«Ø§Ù„ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯ÙŠÙ†
    """
    print("\n" + "="*80)
    print("Example 5: Multi-Agent Monitoring")
    print("Ù…Ø«Ø§Ù„ 5: Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯ÙŠÙ†")
    print("="*80 + "\n")

    monitor = PerformanceMonitor()

    # Simulate multiple agents
    agents = [
        ("disease-expert", "disease_diagnosis"),
        ("irrigation-advisor", "irrigation_planning"),
        ("fertilizer-expert", "fertilization"),
        ("weather-analyst", "weather_analysis"),
    ]

    print(f"ğŸ‘¥ Monitoring {len(agents)} agents\n")

    for agent_id, agent_type in agents:
        # Simulate requests
        for i in range(5):
            request_id = await monitor.record_request(
                agent_id=agent_id,
                request_data={"agent_type": agent_type, "request_num": i+1}
            )

            await monitor.record_response(
                agent_id=agent_id,
                response_data={"result": f"response_{i+1}"},
                success=True,
                latency=1.0 + (i * 0.2),
                confidence=0.8 + (i * 0.02),
                tokens_used=100 + (i * 10)
            )

    # Get all metrics
    all_metrics = await monitor.get_all_metrics()

    print("ğŸ“Š All Agent Metrics:\n")

    for agent_id, metrics in all_metrics.items():
        print(f"  {agent_id}:")
        print(f"    Requests: {metrics.total_requests}")
        print(f"    Success Rate: {metrics.success_rate():.2f}%")
        print(f"    Avg Response Time: {metrics.avg_response_time:.2f}s")
        print(f"    Avg Confidence: {metrics.avg_confidence:.2%}")
        print(f"    Cost: ${metrics.cost_estimate:.4f}")
        print()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Example 6: Metrics Export
# Ù…Ø«Ø§Ù„ 6: ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def example_metrics_export(monitor, agent_id):
    """
    Metrics export example
    Ù…Ø«Ø§Ù„ ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
    """
    print("\n" + "="*80)
    print("Example 6: Metrics Export")
    print("Ù…Ø«Ø§Ù„ 6: ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³")
    print("="*80 + "\n")

    # Export as JSON
    print("ğŸ“„ Exporting metrics as JSON...\n")
    json_export = await monitor.export_metrics(format="json")
    print("JSON Export (first 500 characters):")
    print(json_export[:500] + "...\n")

    # Export as Prometheus (if available)
    if PROMETHEUS_AVAILABLE:
        print("ğŸ“Š Exporting metrics as Prometheus format...\n")
        prom_export = await monitor.export_metrics(format="prometheus")
        print("Prometheus Export (first 800 characters):")
        print(prom_export[:800] + "...\n")
    else:
        print("âš ï¸  Prometheus export not available (prometheus_client not installed)\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main Execution
# Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main():
    """
    Main execution function
    Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    """
    print("\n" + "â•”" + "="*78 + "â•—")
    print("â•‘" + " "*15 + "SAHOOL Multi-Agent Performance Monitor" + " "*24 + "â•‘")
    print("â•‘" + " "*12 + "Ù†Ø¸Ø§Ù… Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù„ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯ Ù„Ø³Ù‡ÙˆÙ„" + " "*19 + "â•‘")
    print("â•š" + "="*78 + "â•\n")

    # Run examples
    try:
        # Example 1: Basic monitoring
        monitor, agent_id = await example_basic_monitoring()

        # Example 2: Feedback collection
        collector = await example_feedback_collection(monitor, agent_id)

        # Example 3: Accuracy tracking
        await example_accuracy_tracking(monitor, collector, agent_id)

        # Example 4: Recommendations
        await example_recommendations(monitor, collector, agent_id)

        # Example 5: Multi-agent monitoring
        await example_multi_agent_monitoring()

        # Example 6: Metrics export
        await example_metrics_export(monitor, agent_id)

        print("\n" + "="*80)
        print("âœ… All examples completed successfully!")
        print("âœ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§ÙƒØªÙ…Ù„Øª Ø¨Ù†Ø¬Ø§Ø­!")
        print("="*80 + "\n")

    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # Run the examples
    asyncio.run(main())
