#!/usr/bin/env python3
"""
SAHOOL Project Analyzer
ÙØ§Ø­Øµ Ù…Ø´Ø±ÙˆØ¹ Ø³Ù‡ÙˆÙ„

Scans the entire project using Code Fix Agent API.
ÙŠÙØ­Øµ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆÙƒÙŠÙ„ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„ÙƒÙˆØ¯.

Usage:
    python scripts/analyze_project.py [--path PATH] [--output OUTPUT]
"""

import argparse
import asyncio
import json
import os
import sys
from datetime import datetime
from pathlib import Path

import httpx

# Configuration
AGENT_URL = os.getenv("CODE_FIX_AGENT_URL", "http://localhost:8090")
SUPPORTED_EXTENSIONS = {
    ".py": "python",
    ".ts": "typescript",
    ".tsx": "typescript",
    ".js": "typescript",
    ".dart": "dart",
}

# Directories to skip
SKIP_DIRS = {
    ".git",
    "node_modules",
    "__pycache__",
    ".venv",
    "venv",
    "dist",
    "build",
    ".next",
    "coverage",
    ".pytest_cache",
    ".mypy_cache",
    "eggs",
    "*.egg-info",
    "archive",  # Skip archived/legacy code
    "vendor",
    "migrations",
}

# Files to skip
SKIP_FILES = {
    "*.min.js",
    "*.bundle.js",
    "package-lock.json",
    "yarn.lock",
}


class ProjectAnalyzer:
    """ÙØ§Ø­Øµ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"""

    def __init__(self, base_url: str = AGENT_URL):
        self.base_url = base_url
        self.results = {
            "scan_time": datetime.utcnow().isoformat(),
            "total_files": 0,
            "files_analyzed": 0,
            "files_with_issues": 0,
            "total_issues": 0,
            "issues_by_severity": {"critical": 0, "high": 0, "medium": 0, "low": 0},
            "issues_by_type": {},
            "files": [],
        }

    def should_skip(self, path: Path) -> bool:
        """Check if path should be skipped"""
        # Skip directories
        for skip_dir in SKIP_DIRS:
            if skip_dir in path.parts:
                return True

        # Skip files
        for skip_file in SKIP_FILES:
            if path.match(skip_file):
                return True

        return False

    def get_language(self, path: Path) -> str | None:
        """Get language from file extension"""
        return SUPPORTED_EXTENSIONS.get(path.suffix.lower())

    async def analyze_file(self, file_path: Path, client: httpx.AsyncClient) -> dict:
        """Analyze a single file"""
        language = self.get_language(file_path)
        if not language:
            return None

        try:
            code = file_path.read_text(encoding="utf-8", errors="ignore")

            # Skip empty or very large files
            if not code.strip():
                return {"skipped": True, "reason": "empty"}
            if len(code) > 100000:
                return {"skipped": True, "reason": "too_large"}

            response = await client.post(
                f"{self.base_url}/api/v1/analyze",
                json={
                    "code": code,
                    "language": language,
                    "file_path": str(file_path),
                },
                timeout=30.0,
            )

            if response.status_code == 200:
                return response.json()
            else:
                return {"error": f"HTTP {response.status_code}"}

        except Exception as e:
            return {"error": str(e)}

    async def scan_directory(self, root_path: Path, max_files: int = 500) -> dict:
        """Scan entire directory"""
        print(f"\nğŸ” ÙØ­Øµ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹: {root_path}")
        print(f"   Scanning project: {root_path}\n")

        files_to_analyze = []

        # Collect files
        for ext in SUPPORTED_EXTENSIONS.keys():
            for file_path in root_path.rglob(f"*{ext}"):
                if not self.should_skip(file_path):
                    files_to_analyze.append(file_path)

        self.results["total_files"] = len(files_to_analyze)

        if len(files_to_analyze) > max_files:
            print(f"âš ï¸  ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(files_to_analyze)} Ù…Ù„ÙØŒ Ø³ÙŠØªÙ… ÙØ­Øµ Ø£ÙˆÙ„ {max_files}")
            files_to_analyze = files_to_analyze[:max_files]

        print(f"ğŸ“ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„ÙØ­Øµ: {len(files_to_analyze)}")
        print("-" * 50)

        async with httpx.AsyncClient() as client:
            # Check if agent is running
            try:
                health = await client.get(f"{self.base_url}/healthz", timeout=5.0)
                if health.status_code != 200:
                    print("âŒ ÙˆÙƒÙŠÙ„ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„ÙƒÙˆØ¯ ØºÙŠØ± Ù…ØªØ§Ø­!")
                    print("   Code Fix Agent is not available!")
                    print(f"   ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„Ù‡ Ø¹Ù„Ù‰: {self.base_url}")
                    return self.results
            except Exception:
                print("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨ÙˆÙƒÙŠÙ„ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„ÙƒÙˆØ¯!")
                print(f"   Cannot connect to Code Fix Agent at {self.base_url}")
                return self.results

            # Analyze files with progress
            for i, file_path in enumerate(files_to_analyze, 1):
                relative_path = file_path.relative_to(root_path)
                print(f"[{i}/{len(files_to_analyze)}] {relative_path}...", end=" ")

                result = await self.analyze_file(file_path, client)

                if result and result.get("skipped"):
                    print(f"â­ï¸  {result.get('reason', 'skipped')}")
                    continue

                if result and result.get("success"):
                    self.results["files_analyzed"] += 1

                    data = result.get("data", {})
                    issues = data.get("issues", [])
                    issues_count = data.get("issues_count", len(issues))

                    if issues_count > 0:
                        self.results["files_with_issues"] += 1
                        self.results["total_issues"] += issues_count

                        # Count by type
                        for issue in issues:
                            issue_type = issue.get("type", "unknown")
                            self.results["issues_by_type"][issue_type] = (
                                self.results["issues_by_type"].get(issue_type, 0) + 1
                            )

                            # Count by severity
                            severity = issue.get("severity", "medium").lower()
                            if severity in self.results["issues_by_severity"]:
                                self.results["issues_by_severity"][severity] += 1

                        print(f"âš ï¸  {issues_count} Ù…Ø´ÙƒÙ„Ø©")

                        self.results["files"].append(
                            {
                                "path": str(relative_path),
                                "language": self.get_language(file_path),
                                "issues_count": issues_count,
                                "issues": issues[:10],  # Limit stored issues
                                "metrics": data.get("metrics", {}),
                            }
                        )
                    else:
                        print("âœ…")
                elif result and result.get("error"):
                    print(f"âŒ {str(result.get('error', ''))[:50]}")
                else:
                    print("â­ï¸  ØªØ®Ø·ÙŠ")

        return self.results

    def generate_report(self, output_path: str = None) -> str:
        """Generate analysis report"""
        report = []
        report.append("=" * 60)
        report.append("ğŸ“Š ØªÙ‚Ø±ÙŠØ± ÙØ­Øµ Ù…Ø´Ø±ÙˆØ¹ Ø³Ù‡ÙˆÙ„")
        report.append("   SAHOOL Project Analysis Report")
        report.append("=" * 60)
        report.append(f"\nâ° ÙˆÙ‚Øª Ø§Ù„ÙØ­Øµ: {self.results['scan_time']}")
        report.append(f"\nğŸ“ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ù„ÙØ§Øª:")
        report.append(f"   - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª: {self.results['total_files']}")
        report.append(f"   - Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙØ­ÙˆØµØ©: {self.results['files_analyzed']}")
        report.append(f"   - Ù…Ù„ÙØ§Øª Ø¨Ù‡Ø§ Ù…Ø´Ø§ÙƒÙ„: {self.results['files_with_issues']}")
        report.append(f"\nğŸ› Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø´Ø§ÙƒÙ„:")
        report.append(f"   - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„: {self.results['total_issues']}")
        report.append(f"\nğŸ“ˆ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø­Ø³Ø¨ Ø§Ù„Ø®Ø·ÙˆØ±Ø©:")
        for severity, count in self.results["issues_by_severity"].items():
            if count > 0:
                emoji = {"critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(
                    severity, "âšª"
                )
                report.append(f"   {emoji} {severity}: {count}")

        if self.results["issues_by_type"]:
            report.append(f"\nğŸ“‹ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹:")
            for issue_type, count in sorted(
                self.results["issues_by_type"].items(), key=lambda x: -x[1]
            )[:10]:
                report.append(f"   - {issue_type}: {count}")

        if self.results["files_with_issues"] > 0:
            report.append(f"\nğŸ“„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø©:")
            for file_info in sorted(
                self.results["files"], key=lambda x: -x["issues_count"]
            )[:20]:
                report.append(f"   - {file_info['path']} ({file_info['issues_count']} Ù…Ø´ÙƒÙ„Ø©)")

        report.append("\n" + "=" * 60)

        report_text = "\n".join(report)

        if output_path:
            # Save JSON results
            json_path = output_path.replace(".txt", ".json")
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(self.results, f, ensure_ascii=False, indent=2)

            # Save text report
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(report_text)

            print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {output_path}")
            print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {json_path}")

        return report_text


async def main():
    parser = argparse.ArgumentParser(description="SAHOOL Project Analyzer")
    parser.add_argument(
        "--path",
        default=".",
        help="Path to project root (default: current directory)",
    )
    parser.add_argument(
        "--output",
        default="analysis_report.txt",
        help="Output file path (default: analysis_report.txt)",
    )
    parser.add_argument(
        "--max-files",
        type=int,
        default=500,
        help="Maximum files to analyze (default: 500)",
    )
    parser.add_argument(
        "--agent-url",
        default=AGENT_URL,
        help=f"Code Fix Agent URL (default: {AGENT_URL})",
    )

    args = parser.parse_args()

    analyzer = ProjectAnalyzer(base_url=args.agent_url)
    root_path = Path(args.path).resolve()

    if not root_path.exists():
        print(f"âŒ Ø§Ù„Ù…Ø³Ø§Ø± ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {root_path}")
        sys.exit(1)

    results = await analyzer.scan_directory(root_path, max_files=args.max_files)
    report = analyzer.generate_report(args.output)

    print(report)


if __name__ == "__main__":
    asyncio.run(main())
